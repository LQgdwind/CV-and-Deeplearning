{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTGf-7jPFAMZ"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/SENets/data/kaggle_cifar10_tiny/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import collections\n",
        "import math\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "def read_csv_labels(fname):\n",
        "    \"\"\"读取fname来给标签字典返回⼀个⽂件名\"\"\"\n",
        "    with open(fname, 'r') as f:\n",
        "        lines = f.readlines()[1:]\n",
        "    tokens = [l.rstrip().split(',') for l in lines]\n",
        "    return dict(((name, label) for name, label in tokens))\n",
        "\n",
        "labels = read_csv_labels(os.path.join(data_dir, 'trainLabels.csv'))\n",
        "\n",
        "def copyfile(filename, target_dir):\n",
        "    \"\"\"将⽂件复制到⽬标⽬录\"\"\"\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    shutil.copy(filename, target_dir)\n",
        "\n",
        "def reorg_train_valid(data_dir, labels, valid_ratio):\n",
        "    \"\"\"Split the validation set out of the original training set.\n",
        "\n",
        "    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n",
        "    # The number of examples of the class that has the fewest examples in the\n",
        "    # training dataset\n",
        "    n = collections.Counter(labels.values()).most_common()[-1][1]\n",
        "    # The number of examples per class for the validation set\n",
        "    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n",
        "    label_count = {}\n",
        "    for train_file in os.listdir(os.path.join(data_dir, 'train')):\n",
        "        label = labels[train_file.split('.')[0]]\n",
        "        fname = os.path.join(data_dir, 'train', train_file)\n",
        "        copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n",
        "                                     'train_valid', label))\n",
        "        if label not in label_count or label_count[label] < n_valid_per_label:\n",
        "            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n",
        "                                         'valid', label))\n",
        "            label_count[label] = label_count.get(label, 0) + 1\n",
        "        else:\n",
        "            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n",
        "                                         'train', label))\n",
        "    return n_valid_per_label\n",
        "\n",
        "def reorg_test(data_dir):\n",
        "    \"\"\"Organize the testing set for data loading during prediction.\n",
        "    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n",
        "    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n",
        "        copyfile(os.path.join(data_dir, 'test', test_file), os.path.join(data_dir, 'train_valid_test', 'test','unknown'))\n",
        "\n",
        "def reorg_data(data_dir, valid_ratio):\n",
        "    labels = read_csv_labels(os.path.join(data_dir, 'trainLabels.csv'))\n",
        "    reorg_train_valid(data_dir, labels, valid_ratio)\n",
        "    reorg_test(data_dir)\n"
      ],
      "metadata": {
        "id": "vYizHTIlFtmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "\n",
        "nn_Module = nn.Module\n",
        "\n",
        "#################   WARNING   ################\n",
        "# The below part is generated automatically through:\n",
        "#    d2lbook build lib\n",
        "# Don't edit it directly\n",
        "\n",
        "import time\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "def accuracy(y_hat, y):\n",
        "    \"\"\"Compute the number of correct predictions.\n",
        "    Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = argmax(y_hat, axis=1)\n",
        "    cmp = astype(y_hat, y.dtype) == y\n",
        "    return float(reduce_sum(astype(cmp, y.dtype)))\n",
        "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
        "    \"\"\"Compute the accuracy for a model on a dataset using a GPU.\n",
        "\n",
        "    Defined in :numref:`sec_lenet`\"\"\"\n",
        "    if isinstance(net, nn.Module):\n",
        "        net.eval()  # Set the model to evaluation mode\n",
        "        if not device:\n",
        "            device = next(iter(net.parameters())).device\n",
        "    # No. of correct predictions, no. of predictions\n",
        "    metric = Accumulator(2)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_iter:\n",
        "            if isinstance(X, list):\n",
        "                # Required for BERT Fine-tuning (to be covered later)\n",
        "                X = [x.to(device) for x in X]\n",
        "            else:\n",
        "                X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            metric.add(accuracy(net(X), y), size(y))\n",
        "    return metric[0] / metric[1]\n",
        "\n",
        "def train_batch(net, X, y, loss, trainer, devices):\n",
        "    \"\"\"Train for a minibatch with mutiple GPUs (defined in Chapter 13).\n",
        "\n",
        "    Defined in :numref:`sec_image_augmentation`\"\"\"\n",
        "    if isinstance(X, list):\n",
        "        # Required for BERT fine-tuning (to be covered later)\n",
        "        X = [x.to(devices[0]) for x in X]\n",
        "    else:\n",
        "        X = X.to(devices[0])\n",
        "    y = y.to(devices[0])\n",
        "    net.train()\n",
        "    trainer.zero_grad()\n",
        "    pred = net(X)\n",
        "    l = loss(pred, y)\n",
        "    l.sum().backward()\n",
        "    trainer.step()\n",
        "    train_loss_sum = l.sum()\n",
        "    train_acc_sum = accuracy(pred, y)\n",
        "    return train_loss_sum, train_acc_sum\n",
        "\n",
        "class Accumulator:\n",
        "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
        "    def __init__(self, n):\n",
        "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
        "        self.data = [0.0] * n\n",
        "\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "\n",
        "    def reset(self):\n",
        "        self.data = [0.0] * len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "class Animator:\n",
        "    \"\"\"For plotting data in animation.\"\"\"\n",
        "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
        "                 ylim=None, xscale='linear', yscale='linear',\n",
        "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
        "                 figsize=(3.5, 2.5)):\n",
        "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
        "        # Incrementally plot multiple lines\n",
        "        if legend is None:\n",
        "            legend = []\n",
        "        use_svg_display()\n",
        "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
        "        if nrows * ncols == 1:\n",
        "            self.axes = [self.axes, ]\n",
        "        # Use a lambda function to capture arguments\n",
        "        self.config_axes = lambda: set_axes(\n",
        "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
        "        self.X, self.Y, self.fmts = None, None, fmts\n",
        "\n",
        "    def add(self, x, y):\n",
        "        # Add multiple data points into the figure\n",
        "        if not hasattr(y, \"__len__\"):\n",
        "            y = [y]\n",
        "        n = len(y)\n",
        "        if not hasattr(x, \"__len__\"):\n",
        "            x = [x] * n\n",
        "        if not self.X:\n",
        "            self.X = [[] for _ in range(n)]\n",
        "        if not self.Y:\n",
        "            self.Y = [[] for _ in range(n)]\n",
        "        for i, (a, b) in enumerate(zip(x, y)):\n",
        "            if a is not None and b is not None:\n",
        "                self.X[i].append(a)\n",
        "                self.Y[i].append(b)\n",
        "        self.axes[0].cla()\n",
        "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
        "            self.axes[0].plot(x, y, fmt)\n",
        "        self.config_axes()\n",
        "        display.display(self.fig)\n",
        "        display.clear_output(wait=True)\n",
        "\n",
        "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
        "    \"\"\"Plot a list of images.\n",
        "\n",
        "    Defined in :numref:`sec_fashion_mnist`\"\"\"\n",
        "    figsize = (num_cols * scale, num_rows * scale)\n",
        "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
        "    axes = axes.flatten()\n",
        "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
        "        if torch.is_tensor(img):\n",
        "            # Tensor Image\n",
        "            ax.imshow(img.numpy())\n",
        "        else:\n",
        "            # PIL Image\n",
        "            ax.imshow(img)\n",
        "        ax.axes.get_xaxis().set_visible(False)\n",
        "        ax.axes.get_yaxis().set_visible(False)\n",
        "        if titles:\n",
        "            ax.set_title(titles[i])\n",
        "    return axes\n",
        "class Timer:\n",
        "    \"\"\"Record multiple running times.\"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"Defined in :numref:`subsec_linear_model`\"\"\"\n",
        "        self.times = []\n",
        "        self.start()\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Start the timer.\"\"\"\n",
        "        self.tik = time.time()\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
        "        self.times.append(time.time() - self.tik)\n",
        "        return self.times[-1]\n",
        "\n",
        "    def avg(self):\n",
        "        \"\"\"Return the average time.\"\"\"\n",
        "        return sum(self.times) / len(self.times)\n",
        "\n",
        "    def sum(self):\n",
        "        \"\"\"Return the sum of time.\"\"\"\n",
        "        return sum(self.times)\n",
        "\n",
        "    def cumsum(self):\n",
        "        \"\"\"Return the accumulated time.\"\"\"\n",
        "        return np.array(self.times).cumsum().tolist()\n",
        "def use_svg_display():\n",
        "    \"\"\"Use the svg format to display a plot in Jupyter.\n",
        "\n",
        "    Defined in :numref:`sec_calculus`\"\"\"\n",
        "    backend_inline.set_matplotlib_formats('svg')\n",
        "\n",
        "def set_figsize(figsize=(3.5, 2.5)):\n",
        "    \"\"\"Set the figure size for matplotlib.\n",
        "\n",
        "    Defined in :numref:`sec_calculus`\"\"\"\n",
        "    use_svg_display()\n",
        "    plt.rcParams['figure.figsize'] = figsize\n",
        "\n",
        "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
        "    \"\"\"Set the axes for matplotlib.\n",
        "\n",
        "    Defined in :numref:`sec_calculus`\"\"\"\n",
        "    axes.set_xlabel(xlabel)\n",
        "    axes.set_ylabel(ylabel)\n",
        "    axes.set_xscale(xscale)\n",
        "    axes.set_yscale(yscale)\n",
        "    axes.set_xlim(xlim)\n",
        "    axes.set_ylim(ylim)\n",
        "    if legend:\n",
        "        axes.legend(legend)\n",
        "    axes.grid()\n",
        "\n",
        "def try_all_gpus():\n",
        "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\n",
        "\n",
        "    Defined in :numref:`sec_use_gpu`\"\"\"\n",
        "    devices = [torch.device(f'cuda:{i}')\n",
        "             for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]\n",
        "\n",
        "ones = torch.ones\n",
        "zeros = torch.zeros\n",
        "tensor = torch.tensor\n",
        "arange = torch.arange\n",
        "meshgrid = torch.meshgrid\n",
        "sin = torch.sin\n",
        "sinh = torch.sinh\n",
        "cos = torch.cos\n",
        "cosh = torch.cosh\n",
        "tanh = torch.tanh\n",
        "linspace = torch.linspace\n",
        "exp = torch.exp\n",
        "log = torch.log\n",
        "normal = torch.normal\n",
        "rand = torch.rand\n",
        "matmul = torch.matmul\n",
        "int32 = torch.int32\n",
        "float32 = torch.float32\n",
        "concat = torch.cat\n",
        "stack = torch.stack\n",
        "abs = torch.abs\n",
        "eye = torch.eye\n",
        "numpy = lambda x, *args, **kwargs: x.detach().numpy(*args, **kwargs)\n",
        "size = lambda x, *args, **kwargs: x.numel(*args, **kwargs)\n",
        "reshape = lambda x, *args, **kwargs: x.reshape(*args, **kwargs)\n",
        "to = lambda x, *args, **kwargs: x.to(*args, **kwargs)\n",
        "reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\n",
        "argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\n",
        "astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\n",
        "transpose = lambda x, *args, **kwargs: x.t(*args, **kwargs)\n"
      ],
      "metadata": {
        "id": "6IS_pXJiLHYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "\n",
        "nn_Module = nn.Module\n",
        "\n",
        "#################   WARNING   ################\n",
        "# The below part is generated automatically through:\n",
        "#    d2lbook build lib\n",
        "# Don't edit it directly\n",
        "\n",
        "import time\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "def accuracy(y_hat, y):\n",
        "    \"\"\"Compute the number of correct predictions.\n",
        "    Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = argmax(y_hat, axis=1)\n",
        "    cmp = astype(y_hat, y.dtype) == y\n",
        "    return float(reduce_sum(astype(cmp, y.dtype)))\n",
        "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
        "    \"\"\"Compute the accuracy for a model on a dataset using a GPU.\n",
        "\n",
        "    Defined in :numref:`sec_lenet`\"\"\"\n",
        "    if isinstance(net, nn.Module):\n",
        "        net.eval()  # Set the model to evaluation mode\n",
        "        if not device:\n",
        "            device = next(iter(net.parameters())).device\n",
        "    # No. of correct predictions, no. of predictions\n",
        "    metric = Accumulator(2)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_iter:\n",
        "            if isinstance(X, list):\n",
        "                # Required for BERT Fine-tuning (to be covered later)\n",
        "                X = [x.to(device) for x in X]\n",
        "            else:\n",
        "                X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            metric.add(accuracy(net(X), y), size(y))\n",
        "    return metric[0] / metric[1]\n",
        "\n",
        "def train_batch(net, X, y, loss, trainer, devices):\n",
        "    \"\"\"Train for a minibatch with mutiple GPUs (defined in Chapter 13).\n",
        "\n",
        "    Defined in :numref:`sec_image_augmentation`\"\"\"\n",
        "    if isinstance(X, list):\n",
        "        # Required for BERT fine-tuning (to be covered later)\n",
        "        X = [x.to(devices[0]) for x in X]\n",
        "    else:\n",
        "        X = X.to(devices[0])\n",
        "    y = y.to(devices[0])\n",
        "    net.train()\n",
        "    trainer.zero_grad()\n",
        "    pred = net(X)\n",
        "    l = loss(pred, y)\n",
        "    l.sum().backward()\n",
        "    trainer.step()\n",
        "    train_loss_sum = l.sum()\n",
        "    train_acc_sum = accuracy(pred, y)\n",
        "    return train_loss_sum, train_acc_sum\n",
        "\n",
        "class Accumulator:\n",
        "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
        "    def __init__(self, n):\n",
        "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
        "        self.data = [0.0] * n\n",
        "\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "\n",
        "    def reset(self):\n",
        "        self.data = [0.0] * len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "class Animator:\n",
        "    \"\"\"For plotting data in animation.\"\"\"\n",
        "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
        "                 ylim=None, xscale='linear', yscale='linear',\n",
        "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
        "                 figsize=(3.5, 2.5)):\n",
        "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
        "        # Incrementally plot multiple lines\n",
        "        if legend is None:\n",
        "            legend = []\n",
        "        use_svg_display()\n",
        "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
        "        if nrows * ncols == 1:\n",
        "            self.axes = [self.axes, ]\n",
        "        # Use a lambda function to capture arguments\n",
        "        self.config_axes = lambda: set_axes(\n",
        "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
        "        self.X, self.Y, self.fmts = None, None, fmts\n",
        "\n",
        "    def add(self, x, y):\n",
        "        # Add multiple data points into the figure\n",
        "        if not hasattr(y, \"__len__\"):\n",
        "            y = [y]\n",
        "        n = len(y)\n",
        "        if not hasattr(x, \"__len__\"):\n",
        "            x = [x] * n\n",
        "        if not self.X:\n",
        "            self.X = [[] for _ in range(n)]\n",
        "        if not self.Y:\n",
        "            self.Y = [[] for _ in range(n)]\n",
        "        for i, (a, b) in enumerate(zip(x, y)):\n",
        "            if a is not None and b is not None:\n",
        "                self.X[i].append(a)\n",
        "                self.Y[i].append(b)\n",
        "        self.axes[0].cla()\n",
        "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
        "            self.axes[0].plot(x, y, fmt)\n",
        "        self.config_axes()\n",
        "        display.display(self.fig)\n",
        "        display.clear_output(wait=True)\n",
        "\n",
        "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
        "    \"\"\"Plot a list of images.\n",
        "\n",
        "    Defined in :numref:`sec_fashion_mnist`\"\"\"\n",
        "    figsize = (num_cols * scale, num_rows * scale)\n",
        "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
        "    axes = axes.flatten()\n",
        "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
        "        if torch.is_tensor(img):\n",
        "            # Tensor Image\n",
        "            ax.imshow(img.numpy())\n",
        "        else:\n",
        "            # PIL Image\n",
        "            ax.imshow(img)\n",
        "        ax.axes.get_xaxis().set_visible(False)\n",
        "        ax.axes.get_yaxis().set_visible(False)\n",
        "        if titles:\n",
        "            ax.set_title(titles[i])\n",
        "    return axes\n",
        "class Timer:\n",
        "    \"\"\"Record multiple running times.\"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"Defined in :numref:`subsec_linear_model`\"\"\"\n",
        "        self.times = []\n",
        "        self.start()\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Start the timer.\"\"\"\n",
        "        self.tik = time.time()\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
        "        self.times.append(time.time() - self.tik)\n",
        "        return self.times[-1]\n",
        "\n",
        "    def avg(self):\n",
        "        \"\"\"Return the average time.\"\"\"\n",
        "        return sum(self.times) / len(self.times)\n",
        "\n",
        "    def sum(self):\n",
        "        \"\"\"Return the sum of time.\"\"\"\n",
        "        return sum(self.times)\n",
        "\n",
        "    def cumsum(self):\n",
        "        \"\"\"Return the accumulated time.\"\"\"\n",
        "        return np.array(self.times).cumsum().tolist()\n",
        "def use_svg_display():\n",
        "    \"\"\"Use the svg format to display a plot in Jupyter.\n",
        "\n",
        "    Defined in :numref:`sec_calculus`\"\"\"\n",
        "    pass\n",
        "\n",
        "def set_figsize(figsize=(3.5, 2.5)):\n",
        "    \"\"\"Set the figure size for matplotlib.\n",
        "\n",
        "    Defined in :numref:`sec_calculus`\"\"\"\n",
        "    use_svg_display()\n",
        "    plt.rcParams['figure.figsize'] = figsize\n",
        "\n",
        "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
        "    \"\"\"Set the axes for matplotlib.\n",
        "\n",
        "    Defined in :numref:`sec_calculus`\"\"\"\n",
        "    axes.set_xlabel(xlabel)\n",
        "    axes.set_ylabel(ylabel)\n",
        "    axes.set_xscale(xscale)\n",
        "    axes.set_yscale(yscale)\n",
        "    axes.set_xlim(xlim)\n",
        "    axes.set_ylim(ylim)\n",
        "    if legend:\n",
        "        axes.legend(legend)\n",
        "    axes.grid()\n",
        "\n",
        "def try_all_gpus():\n",
        "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\n",
        "\n",
        "    Defined in :numref:`sec_use_gpu`\"\"\"\n",
        "    devices = [torch.device(f'cuda:{i}')\n",
        "             for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]\n",
        "\n",
        "ones = torch.ones\n",
        "zeros = torch.zeros\n",
        "tensor = torch.tensor\n",
        "arange = torch.arange\n",
        "meshgrid = torch.meshgrid\n",
        "sin = torch.sin\n",
        "sinh = torch.sinh\n",
        "cos = torch.cos\n",
        "cosh = torch.cosh\n",
        "tanh = torch.tanh\n",
        "linspace = torch.linspace\n",
        "exp = torch.exp\n",
        "log = torch.log\n",
        "normal = torch.normal\n",
        "rand = torch.rand\n",
        "matmul = torch.matmul\n",
        "int32 = torch.int32\n",
        "float32 = torch.float32\n",
        "concat = torch.cat\n",
        "stack = torch.stack\n",
        "abs = torch.abs\n",
        "eye = torch.eye\n",
        "numpy = lambda x, *args, **kwargs: x.detach().numpy(*args, **kwargs)\n",
        "size = lambda x, *args, **kwargs: x.numel(*args, **kwargs)\n",
        "reshape = lambda x, *args, **kwargs: x.reshape(*args, **kwargs)\n",
        "to = lambda x, *args, **kwargs: x.to(*args, **kwargs)\n",
        "reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\n",
        "argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\n",
        "astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\n",
        "transpose = lambda x, *args, **kwargs: x.t(*args, **kwargs)\n"
      ],
      "metadata": {
        "id": "OpHLke2eLP49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DyReLU(nn.Module):\n",
        "    def __init__(self, channels, reduction=4, k=2, conv_type='2d'):\n",
        "        super(DyReLU, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.k = k\n",
        "        self.conv_type = conv_type\n",
        "        assert self.conv_type in ['1d', '2d']\n",
        "\n",
        "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Linear(channels // reduction, 2*k)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.register_buffer('lambdas', torch.Tensor([1.]*k + [0.5]*k).float())\n",
        "        self.register_buffer('init_v', torch.Tensor([1.] + [0.]*(2*k - 1)).float())\n",
        "\n",
        "    def get_relu_coefs(self, x):\n",
        "        theta = torch.mean(x, axis=-1)\n",
        "        if self.conv_type == '2d':\n",
        "            theta = torch.mean(theta, axis=-1)\n",
        "        theta = self.fc1(theta)\n",
        "        theta = self.relu(theta)\n",
        "        theta = self.fc2(theta)\n",
        "        theta = 2 * self.sigmoid(theta) - 1\n",
        "        return theta\n",
        "\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class DyReLUA(DyReLU):\n",
        "    def __init__(self, channels, reduction=4, k=2, conv_type='2d'):\n",
        "        super(DyReLUA, self).__init__(channels, reduction, k, conv_type)\n",
        "        self.fc2 = nn.Linear(channels // reduction, 2*k)\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert x.shape[1] == self.channels\n",
        "        theta = self.get_relu_coefs(x)\n",
        "\n",
        "        relu_coefs = theta.view(-1, 2*self.k) * self.lambdas + self.init_v\n",
        "        # BxCxL -> LxCxBx1\n",
        "        x_perm = x.transpose(0, -1).unsqueeze(-1)\n",
        "        output = x_perm * relu_coefs[:, :self.k] + relu_coefs[:, self.k:]\n",
        "        # LxCxBx2 -> BxCxL\n",
        "        result = torch.max(output, dim=-1)[0].transpose(0, -1)\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "class DyReLUB(DyReLU):\n",
        "    def __init__(self, channels, reduction=4, k=2, conv_type='2d'):\n",
        "        super(DyReLUB, self).__init__(channels, reduction, k, conv_type)\n",
        "        self.fc2 = nn.Linear(channels // reduction, 2*k*channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert x.shape[1] == self.channels\n",
        "        theta = self.get_relu_coefs(x)\n",
        "\n",
        "        relu_coefs = theta.view(-1, self.channels, 2*self.k) * self.lambdas + self.init_v\n",
        "\n",
        "        if self.conv_type == '1d':\n",
        "            # BxCxL -> LxBxCx1\n",
        "            x_perm = x.permute(2, 0, 1).unsqueeze(-1)\n",
        "            output = x_perm * relu_coefs[:, :, :self.k] + relu_coefs[:, :, self.k:]\n",
        "            # LxBxCx2 -> BxCxL\n",
        "            result = torch.max(output, dim=-1)[0].permute(1, 2, 0)\n",
        "\n",
        "        elif self.conv_type == '2d':\n",
        "            # BxCxHxW -> HxWxBxCx1\n",
        "            x_perm = x.permute(2, 3, 0, 1).unsqueeze(-1)\n",
        "            output = x_perm * relu_coefs[:, :, :self.k] + relu_coefs[:, :, self.k:]\n",
        "            # HxWxBxCx2 -> BxCxHxW\n",
        "            result = torch.max(output, dim=-1)[0].permute(2, 3, 0, 1)\n",
        "\n",
        "        return result\n"
      ],
      "metadata": {
        "id": "-WLCxCEitDi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import init\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "import math\n",
        "\n",
        "\n",
        "class Maxout(nn.Module):\n",
        "    __constants__ = ['bias']\n",
        "\n",
        "    def __init__(self, in_features, out_features, pieces, bias=True):\n",
        "        super(Maxout, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.pieces = pieces\n",
        "        self.weight = Parameter(torch.Tensor(pieces, out_features, in_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(pieces, out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input.matmul(self.weight.permute(0, 2, 1)).permute((1, 0, 2)) + self.bias\n",
        "        output = torch.max(output, dim=1)[0]\n",
        "        return output"
      ],
      "metadata": {
        "id": "UuW-mCaXOJaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "# 调用torchvision自带的resnet模型用作对比\n",
        "def resnet_18():\n",
        "    return torchvision.models.resnet18(pretrained=False)\n",
        "\n",
        "\n",
        "def resnet_50():\n",
        "    return torchvision.models.resnet50(pretrained=False)\n"
      ],
      "metadata": {
        "id": "FJvivQ7COXjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "        if planes == 64:\n",
        "            self.globalAvgPool = nn.AvgPool2d(56, stride=1)\n",
        "        elif planes == 128:\n",
        "            self.globalAvgPool = nn.AvgPool2d(28, stride=1)\n",
        "        elif planes == 256:\n",
        "            self.globalAvgPool = nn.AvgPool2d(14, stride=1)\n",
        "        elif planes == 512:\n",
        "            self.globalAvgPool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc1 = nn.Linear(in_features=planes, out_features=round(planes / 16))\n",
        "        self.fc2 = nn.Linear(in_features=round(planes / 16), out_features=planes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        original_out = out\n",
        "        out = self.globalAvgPool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0), out.size(1), 1, 1)\n",
        "        out = out * original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        if planes == 64:\n",
        "            self.globalAvgPool = nn.AvgPool2d(56, stride=1)\n",
        "        elif planes == 128:\n",
        "            self.globalAvgPool = nn.AvgPool2d(28, stride=1)\n",
        "        elif planes == 256:\n",
        "            self.globalAvgPool = nn.AvgPool2d(14, stride=1)\n",
        "        elif planes == 512:\n",
        "            self.globalAvgPool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc1 = nn.Linear(in_features=planes * 4, out_features=round(planes / 4))\n",
        "        self.fc2 = nn.Linear(in_features=round(planes / 4), out_features=planes * 4)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "     \n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        original_out = out\n",
        "        out = self.globalAvgPool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0),out.size(1),1,1)\n",
        "        out = out * original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class SENet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(SENet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.size())\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        # print(x.size())\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        # print(x.size())\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "       #  print(x.size())\n",
        "       #  print(\"ok\")\n",
        "        return x\n",
        "\n",
        "\n",
        "def se_resnet_18(pretrained=False, **kwargs):\n",
        "    model = SENet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def se_resnet_34(pretrained=False, **kwargs):\n",
        "    model = SENet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def se_resnet_50(pretrained=False, **kwargs):\n",
        "    model = SENet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def se_resnet_101(pretrained=False, **kwargs):\n",
        "    model = SENet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def se_resnet_152(pretrained=False, **kwargs):\n",
        "    model = SENet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "lUNCeA3uLUww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock_idea1(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock_idea1, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dyrelu1 = DyReLUB(planes)\n",
        "        self.dyrelu2 = DyReLUB(round(planes / 16))\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "        if planes == 64:\n",
        "            self.globalAvgPool = nn.AvgPool2d(56, stride=1)\n",
        "        elif planes == 128:\n",
        "            self.globalAvgPool = nn.AvgPool2d(28, stride=1)\n",
        "        elif planes == 256:\n",
        "            self.globalAvgPool = nn.AvgPool2d(14, stride=1)\n",
        "        elif planes == 512:\n",
        "            self.globalAvgPool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc1 = nn.Linear(in_features=planes, out_features=round(planes / 16))\n",
        "        self.fc2 = nn.Linear(in_features=round(planes / 16), out_features=planes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.dyrelu1(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        original_out = out\n",
        "        out = self.globalAvgPool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = out.view(out.size(0),out.size(1) , 1, 1)\n",
        "        out = self.dyrelu2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0), out.size(1), 1, 1)\n",
        "        out = out * original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck_idea1(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck_idea1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dyrelu1 = DyReLUB(planes)\n",
        "        self.dyrelu2 = DyReLUB(round(planes / 16))\n",
        "        if planes == 64:\n",
        "            self.globalAvgPool = nn.AvgPool2d(56, stride=1)\n",
        "        elif planes == 128:\n",
        "            self.globalAvgPool = nn.AvgPool2d(28, stride=1)\n",
        "        elif planes == 256:\n",
        "            self.globalAvgPool = nn.AvgPool2d(14, stride=1)\n",
        "        elif planes == 512:\n",
        "            self.globalAvgPool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc1 = nn.Linear(in_features=planes * 4, out_features=round(planes / 4))\n",
        "        self.fc2 = nn.Linear(in_features=round(planes / 4), out_features=planes * 4)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.dyrelu1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.dyrelu1(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        original_out = out\n",
        "        out = self.globalAvgPool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = out.view(out.size(0), out.size(1), 1, 1)\n",
        "        out = self.dyrelu2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0),out.size(1),1,1)\n",
        "        out = out * original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class SENet_idea1(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(SENet_idea1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def se_resnet_18_idea1( **kwargs):\n",
        "    model = SENet_idea1(BasicBlock_idea1, [2, 2, 2, 2], **kwargs)\n",
        "    return model\n",
        "\n",
        "def se_resnet_50_idea1( **kwargs):\n",
        "    model = SENet_idea1(Bottleneck_idea1, [3, 4, 6, 3], **kwargs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "I4SenmUgO76o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock_idea2(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock_idea2, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "        if planes == 64:\n",
        "            self.globalAvgPool = nn.AvgPool2d(56, stride=1)\n",
        "        elif planes == 128:\n",
        "            self.globalAvgPool = nn.AvgPool2d(28, stride=1)\n",
        "        elif planes == 256:\n",
        "            self.globalAvgPool = nn.AvgPool2d(14, stride=1)\n",
        "        elif planes == 512:\n",
        "            self.globalAvgPool = nn.AvgPool2d(7, stride=1)\n",
        "        self.seconv = nn.Conv1d(planes,planes,kernel_size=5,padding=2)\n",
        "        # 设置一个静态的一维卷积层seconv\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        original_out = out\n",
        "        out = self.globalAvgPool(out)\n",
        "        out = out.view(out.size(0), out.size(1), -1)\n",
        "        out = self.seconv(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0), out.size(1), 1, 1)\n",
        "        out = out * original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck_idea2(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck_idea2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        if planes == 64:\n",
        "            self.globalAvgPool = nn.AvgPool2d(56, stride=1)\n",
        "        elif planes == 128:\n",
        "            self.globalAvgPool = nn.AvgPool2d(28, stride=1)\n",
        "        elif planes == 256:\n",
        "            self.globalAvgPool = nn.AvgPool2d(14, stride=1)\n",
        "        elif planes == 512:\n",
        "            self.globalAvgPool = nn.AvgPool2d(7, stride=1)\n",
        "\n",
        "        self.seconv = nn.Conv1d(planes,planes,kernel_size=5,padding=2)\n",
        "        # 设置一个静态的一维卷积层seconv\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        original_out = out\n",
        "        out = self.globalAvgPool(out)\n",
        "        out = out.view(out.size(0), out.size(1), -1)\n",
        "        out = self.seconv(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0),out.size(1),1,1)\n",
        "        out = out * original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class SENet_idea2(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(SENet_idea2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def se_resnet_18_idea2( **kwargs):\n",
        "    model = SENet_idea2(BasicBlock_idea2, [2, 2, 2, 2], **kwargs)\n",
        "    return model\n",
        "\n",
        "def se_resnet_50_idea2( **kwargs):\n",
        "    model = SENet_idea2(Bottleneck_idea2, [3, 4, 6, 3], **kwargs)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "SvECyZapvz7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock_idea3(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock_idea3, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "        if planes == 64:\n",
        "            self.globalAvgPool = nn.AvgPool2d(56, stride=1)\n",
        "        elif planes == 128:\n",
        "            self.globalAvgPool = nn.AvgPool2d(28, stride=1)\n",
        "        elif planes == 256:\n",
        "            self.globalAvgPool = nn.AvgPool2d(14, stride=1)\n",
        "        elif planes == 512:\n",
        "            self.globalAvgPool = nn.AvgPool2d(7, stride=1)\n",
        "        self.seconv1 = nn.Conv1d(planes,planes,kernel_size=5,padding=2)\n",
        "        self.seconv2 = nn.Conv1d(planes, planes, kernel_size=5, padding=2)\n",
        "        # 设置两个个静态的一维卷积层seconv\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        original_out = out\n",
        "        out = self.globalAvgPool(out)\n",
        "        out = out.view(out.size(0), out.size(1), -1)\n",
        "        out = self.seconv1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.seconv2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0), out.size(1), 1, 1)\n",
        "        out = out * original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck_idea3(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck_idea3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        if planes == 64:\n",
        "            self.globalAvgPool = nn.AvgPool2d(56, stride=1)\n",
        "        elif planes == 128:\n",
        "            self.globalAvgPool = nn.AvgPool2d(28, stride=1)\n",
        "        elif planes == 256:\n",
        "            self.globalAvgPool = nn.AvgPool2d(14, stride=1)\n",
        "        elif planes == 512:\n",
        "            self.globalAvgPool = nn.AvgPool2d(7, stride=1)\n",
        "\n",
        "        self.seconv1 = nn.Conv1d(planes,planes,kernel_size=5,padding=2)\n",
        "        self.seconv2 = nn.Conv1d(planes, planes, kernel_size=5, padding=2)\n",
        "        # 设置二个静态的一维卷积层seconv\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        original_out = out\n",
        "        out = self.globalAvgPool(out)\n",
        "        out = out.view(out.size(0), out.size(1), -1)\n",
        "        out = self.seconv1(out)\n",
        "        out = self.relu()\n",
        "        out = self.seconv2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0),out.size(1),1,1)\n",
        "        out = out * original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class SENet_idea3(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(SENet_idea3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def se_resnet_18_idea3( **kwargs):\n",
        "    model = SENet_idea3(BasicBlock_idea3, [2, 2, 2, 2], **kwargs)\n",
        "    return model\n",
        "\n",
        "def se_resnet_50_idea3( **kwargs):\n",
        "    model = SENet_idea3(Bottleneck_idea3, [3, 4, 6, 3], **kwargs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "ivm_QK08LQvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock_idea4(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock_idea4, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "        if planes == 64:\n",
        "            self.globalMaxPool = nn.MaxPool2d(56, stride=1)\n",
        "        elif planes == 128:\n",
        "            self.globalMaxPool = nn.MaxPool2d(28, stride=1)\n",
        "        elif planes == 256:\n",
        "            self.globalMaxPool = nn.MaxPool2d(14, stride=1)\n",
        "        elif planes == 512:\n",
        "            self.globalMaxPool = nn.MaxPool2d(7, stride=1)\n",
        "        self.fc1 = nn.Linear(in_features=planes, out_features=round(planes / 16))\n",
        "        self.fc2 = nn.Linear(in_features=round(planes / 16), out_features=planes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        original_out = out\n",
        "        out = self.globalMaxPool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0), out.size(1), 1, 1)\n",
        "        out = out * original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck_idea4(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck_idea4, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        if planes == 64:\n",
        "            self.globalMaxPool = nn.MaxPool2d(56, stride=1)\n",
        "        elif planes == 128:\n",
        "            self.globalMaxPool = nn.MaxPool2d(28, stride=1)\n",
        "        elif planes == 256:\n",
        "            self.globalMaxPool = nn.MaxPool2d(14, stride=1)\n",
        "        elif planes == 512:\n",
        "            self.globalMaxPool = nn.MaxPool2d(7, stride=1)\n",
        "        self.fc1 = nn.Linear(in_features=planes * 4, out_features=round(planes / 4))\n",
        "        self.fc2 = nn.Linear(in_features=round(planes / 4), out_features=planes * 4)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        original_out = out\n",
        "        out = self.globalMaxPool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0), out.size(1), 1, 1)\n",
        "        out = out * original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class SENet_idea4(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(SENet_idea4, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.Maxpool = nn.MaxPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.Maxpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def se_resnet_18_idea4(**kwargs):\n",
        "    model = SENet_idea4(BasicBlock_idea4, [2, 2, 2, 2], **kwargs)\n",
        "    return model\n",
        "\n",
        "def se_resnet_50_idea4(**kwargs):\n",
        "    model = SENet_idea4(Bottleneck_idea4, [3, 4, 6, 3], **kwargs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "x67Z7f1FLYXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock_idea5(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock_idea5, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "        if planes == 64:\n",
        "            self.globalAvgPool = nn.AvgPool2d(56, stride=1)\n",
        "        elif planes == 128:\n",
        "            self.globalAvgPool = nn.AvgPool2d(28, stride=1)\n",
        "        elif planes == 256:\n",
        "            self.globalAvgPool = nn.AvgPool2d(14, stride=1)\n",
        "        elif planes == 512:\n",
        "            self.globalAvgPool = nn.AvgPool2d(7, stride=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.maxout1 = Maxout(in_features=planes, out_features=round(planes / 16), pieces=10)\n",
        "        self.maxout2 = Maxout(in_features=round(planes / 16), out_features=planes,pieces=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        original_out = out\n",
        "        out = self.globalAvgPool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.maxout1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.maxout2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = out.view(out.size(0), out.size(1), 1, 1)\n",
        "        out = out * original_out\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class SENet_idea5(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(SENet_idea5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def se_resnet_18_idea5(**kwargs):\n",
        "    model = SENet_idea5(BasicBlock_idea5, [2, 2, 2, 2], **kwargs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "tKj3FmNTLbvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "\n",
        "batch_size = 32\n",
        "valid_ratio = 0.1\n",
        "\n",
        "reorg_data(data_dir, valid_ratio)\n",
        "\n",
        "transform_train = torchvision.transforms.Compose([\n",
        "torchvision.transforms.Resize([224,224]),\n",
        "torchvision.transforms.RandomHorizontalFlip(),\n",
        "torchvision.transforms.ToTensor(),\n",
        "torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],[0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "transform_test = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],[0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train_valid_test', folder),transform=transform_train) for folder in ['train', 'train_valid']]\n",
        "\n",
        "valid_ds, test_ds = [torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train_valid_test', folder),transform=transform_test) for folder in ['valid', 'test']]\n",
        "\n",
        "train_iter, train_valid_iter = [torch.utils.data.DataLoader(dataset, batch_size, shuffle=True, drop_last=True) for dataset in (train_ds, train_valid_ds)]\n",
        "\n",
        "valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,drop_last=True)\n",
        "\n",
        "test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,drop_last=False)\n",
        "\n",
        "net = se_resnet_18()\n",
        "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "\n",
        "\n",
        "def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,lr_decay):\n",
        "    trainer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9,weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay)\n",
        "    num_batches, timer = len(train_iter), Timer()\n",
        "    legend = ['train loss', 'train acc']\n",
        "    if valid_iter is not None:\n",
        "        legend.append('valid acc')\n",
        "    animator =Animator(xlabel='epoch', xlim=[1, num_epochs],legend=legend)\n",
        "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        metric = Accumulator(3)\n",
        "        for i, (features, labels) in enumerate(train_iter):\n",
        "            timer.start()\n",
        "            l, acc = train_batch(net, features, labels,loss, trainer, devices)\n",
        "            metric.add(l, acc, labels.shape[0])\n",
        "            timer.stop()\n",
        "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
        "                animator.add(epoch + (i + 1) / num_batches,(metric[0] / metric[2], metric[1] / metric[2],None))\n",
        "        if valid_iter is not None:\n",
        "            valid_acc = evaluate_accuracy_gpu(net, valid_iter)\n",
        "            animator.add(epoch + 1, (None, None, valid_acc))\n",
        "        scheduler.step()\n",
        "        print(\"epoch : {arg1}\".format(arg1=epoch))\n",
        "    measures = (f'train loss {metric[0] / metric[2]:.3f}, ' f'train acc {metric[1] / metric[2]:.3f}')\n",
        "    if valid_iter is not None:\n",
        "            measures += f', valid acc {valid_acc:.3f}'\n",
        "    print(measures + f'\\n{metric[2] * num_epochs / timer.sum():.1f}' f' examples/sec on {str(devices)}')\n",
        "\n",
        "devices, num_epochs, lr, wd = try_all_gpus(), 100, 2e-4, 5e-4\n",
        "lr_period, lr_decay = 4, 0.9\n",
        "train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,lr_decay)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "lNOMxSTxLcKQ",
        "outputId": "3a8d62c2-af13-4c48-e7fe-e51bb63a70e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 99\n",
            "train loss 0.008, train acc 1.000, valid acc 0.870\n",
            "930.0 examples/sec on [device(type='cuda', index=0)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 252x180 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAuFeIXoL1Uk",
        "outputId": "e14d87d7-12c9-4e2c-f2f2-1ab745a925a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VUtsAFvvVVMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0adc91-3f94-442b-b62b-40c91996b88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}